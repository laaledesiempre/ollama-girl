# Important

This is for fun, feel free to improove or add features. this is a really really simple program right now.

Steps to run it:

1. Run ollama local server.
2. Get the model you want to run.
3. Set the model on the config.json file
4. excecute the program

# Disclaimer.
To run it you need linux, mac or Windows subsystem for linux. because ollama does not have windows support yet.
